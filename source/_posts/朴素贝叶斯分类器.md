---
title: 朴素贝叶斯分类器
id: 1
categories:
  - Machine Learning
date: 2016-04-08 23:50:05
tags:
  - Machine Learning
mathjax: true
---

## 简述

朴素贝叶斯分类器是机器学习中最基础的分类算法了，之前一直忽视这个算法，感觉这种简单利用贝叶斯公式的方法的确很Naive。但是事实上这个算法在对于特征相互独立的分类问题来说还是非常好用的。其基本思想就是在给定在各种情况下一个事件发生的先验概率的情况下，套用贝叶斯公式求出给定各种情况下给定事件发生的后验概率。思想非常简单，但是在某些情况下效果还是非常好的，值得掌握。


## 贝叶斯公式

贝叶斯公式很简单了，对于事件A和事件B，下面的公式显然成立：

$$P(A|B)=\frac{P(A)P(B|A)}{P(B)}$$

这也基本不用证明，分母移过来两边就显然相等了。

在实际应用中，只要把事件B换成$F_1F_2F_3...F_n$等几个特征就可以了。有了这个公式，对于有互不相关的离散特征的分类问题就可以对数据进行简单统计然后对于给定特征求出预期事件了。

## 连续特征处理

从贝叶斯公式的使用可以了解到，这个方法只能处理离散性质的问题，比如性别、身份、地区等特征，但是对于类似年龄、身高、体重等连续性比较强的特征就不太好用概率来表示了。这时通常有下面两种处理方式：

**分段处理**

比如对于年龄，可以分为[0-10],[10-20],[20-30]。。。等较小的区间，这样就可以把他看成是一个离散的特征了。

**高斯化处理**

把连续的值看成是近似高斯分布，求出均值和标准差（最大似然值），这样对于某一个值我们就可以求出一个值，用这个值来表示概率即可。

## 除零问题处理

很明显，在某些特殊的情况下贝叶斯分类器的分母可能为零，这样就会导致一些不令人愉悦的错误。这时我们只要将所有的计数都加一，这样在数据较大时就完全可以忽略这点误差，这就叫**Laplace校准**。


上面就是朴素贝叶斯分类的基本内容，相比与这个“朴素”的算法，还有一个应用贝叶斯公式的算法叫“**贝叶斯网络**”，暂时还没研究到，以后有机会再来学习。

## 相关参考

[Scikit-learn:Naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html)
[分类算法之朴素贝叶斯分类](http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html)
[用Python开始机器学习之朴素贝叶斯分类器](http://blog.csdn.net/lsldd/article/details/41542107)
[朴素贝叶斯分类器的应用](http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html)
