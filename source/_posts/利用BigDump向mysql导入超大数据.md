---
title: 利用BigDump向mysql导入超大数据
id: 1
categories:
  - Database
date: 2015-11-05 17:16:00
tags:
  - Linux
  - Database
---

本来就只想轻轻松松把服务器的mysql数据导入到本地的mysql里的，结果发现这个问题还是一个坑。phpmyadmin里把导入数据的大小限定为了2M，然而我的数据有4M。想分表导入结果发现有一个表的大小还是超过了传输上限。百度了以下据说可以通过修改php和phpmyadmin的配置文件来略微的扩容，结果配置了半天头都大了而且还没有用，后来据说可以通过配置主从服务器来传输，但是那个从服务器的配置始终弄不对（其实是对这种设置的用途理解不够）。最后终于还是用了第三方的脚本，这也是无奈之举，不过用了才知道还是很方便的。

BigDump.php脚本源码在官网下载[Bigdump](http://www.ozerov.de/bigdump/)。（其实只有1000多行，本来打算直接贴过来的，但是发现这里的文本编辑器会对一些字符进行转义，导致保存下来的文件不正确，后来有一次用的时候才发现问题，于是直接贴一下官网地址，也方便以后查询更新。）

使用之前需要稍微进行一下配置（这是显然的，要不然怎么知道写到哪个数据库里），在文件中的40行左右找到以下几项：
```
$db_server   = '';
$db_name     = '';
$db_username = '';
$db_password = '';
```
分别填入ip（本机的当然写localhost），数据库的库名，登陆的用户名，密码。

这样就算配置完成了，接下来只要把这个文件放在站点的某个位置里（为了能通过浏览器访问到），再把需要导入的.sql文件放在同文件夹下即可，通过浏览器访问这个文件，找到需要导入的数据库，点击根据提示操作就行了。